# CNN Training System with PyTorch

CNN model training system (MobileNetV2 and VGG16) using PyTorch, following Clean Architecture.

## Project Structure

```
cnn/
├── src/
│   ├── domain/           # Domain layer (entities and interfaces)
│   ├── data/             # Data layer (datasets and dataloaders)
│   ├── use_cases/        # Use cases (training and early stopping)
│   ├── infrastructure/   # Infrastructure layer (models and checkpoints)
│   └── presentation/     # Presentation layer (CLI and progress)
├── scripts/
│   └── test_image.py     # Script to test individual images
├── main.py               # Main entry point
└── pyproject.toml        # Dependencies
```

## Installation

```bash
# Install dependencies using uv (recommended)
uv sync

# Or using pip
pip install -e .
```

## Data Structure

The system expects data organized by the structure generated by the Rust script:

```
compressed/
├── q1/                    # Quality 1
│   ├── train/
│   │   ├── class1/
│   │   │   ├── img1.jpg
│   │   │   └── img2.jpg
│   │   └── class2/
│   │       └── ...
│   ├── val/
│   │   ├── class1/
│   │   └── class2/
│   └── test/ (optional)
├── q5/                    # Quality 5
└── q10/                   # Quality 10
```

## Usage

### Training

```bash
# Train MobileNetV2 with quality 1
python main.py --model MobileNetV2 --data_dir ./compressed --quality 1 --epochs 50

# Train VGG16 with quality 5 and custom early stopping
python main.py --model VGG16 --data_dir ./compressed --quality 5 --epochs 100 --patience 10 --min_delta 0.001

# With custom parameters
python main.py \
    --model MobileNetV2 \
    --data_dir ./compressed \
    --quality 1 \
    --epochs 50 \
    --batch_size 32 \
    --learning_rate 0.001 \
    --patience 5 \
    --min_delta 0.001 \
    --output_dir out
```

### Test Individual Image

```bash
# Test an image with trained model
python scripts/test_image.py \
    --model_path out/MobileNetV2/best.pt \
    --image_path my_image.jpg

# Specify classes file manually
python scripts/test_image.py \
    --model_path out/VGG16/best.pt \
    --image_path my_image.jpg \
    --classes_file out/VGG16/classes.json
```

## Training Parameters

- `--model`: Model to train (MobileNetV2 or VGG16)
- `--data_dir`: Base directory of compressed data
- `--quality`: Image quality (1, 5, or 10)
- `--epochs`: Maximum number of epochs (default: 50)
- `--batch_size`: Batch size (default: 32)
- `--learning_rate`: Learning rate (default: 0.001)
- `--patience`: Epochs without improvement for early stopping (default: 5)
- `--min_delta`: Minimum improvement considered (default: 0.001)
- `--output_dir`: Output directory (default: out/)
- `--num_workers`: Workers for data loading (default: 4)

## Output

Trained models are saved in:

```
out/
└── {model_name}/
    ├── best.pt          # Best model (lowest val_loss)
    ├── last.pt          # Last checkpoint
    ├── classes.json     # Class mapping
    └── info.json        # Best model information
```

## Features

- ✅ Clean Architecture with clear separation of responsibilities
- ✅ Support for MobileNetV2 and VGG16
- ✅ Configurable early stopping
- ✅ Visual progress during training (tqdm)
- ✅ Automatic class detection
- ✅ Transfer learning with pre-trained models
- ✅ Script to test individual images
- ✅ Well-documented code in Portuguese
